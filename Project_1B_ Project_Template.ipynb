{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\htrujillo\\Udacity\\projects\\data-engineering\\02-Data-Modeling-with-Cassandra\\Sparkify-Cassandra\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "#### Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_keyspace(\n",
    "        keyspace: str,\n",
    "        session: cassandra.cluster.Session\n",
    ") -> int:\n",
    "    \"\"\"This function creates a cassandra keyspace.\n",
    "\n",
    "    Args:\n",
    "        keyspace: keyspace name.\n",
    "        session: Cassandra's cluster session.\n",
    "\n",
    "    \"\"\"\n",
    "    query = f\"CREATE KEYSPACE IF NOT EXISTS {keyspace}\"\n",
    "    query += \" WITH REPLICATION = \"\n",
    "    query += \"{'class': 'SimpleStrategy', 'replication_factor': 1}\"\n",
    "    try:\n",
    "        session.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return 0\n",
    "\n",
    "create_keyspace(\n",
    "    keyspace='sparkify',\n",
    "    session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_keyspace(\n",
    "        keyspace: str,\n",
    "        session: cassandra.cluster.Session\n",
    ") -> int:\n",
    "    \"\"\"This function set the session' keyspace.\n",
    "\n",
    "    Args:\n",
    "        keyspace: keyspace name.\n",
    "        session: Cassandra's cluster session.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session.set_keyspace(keyspace)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return 0\n",
    "\n",
    "set_keyspace(\n",
    "    keyspace='sparkify',\n",
    "    session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling with Cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create queries to ask the following three questions of the data\n",
    "\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Classes\n",
    "\n",
    "To facilitate the Data modeling and database querying, I have created two classes:\n",
    "\n",
    "* CassandraTable: This class provides an interface based on Python's Builder Pattern to facilitate table creation.\n",
    "* Query: This class provides an interface based on Python's Builder Pattern to facilitate query creation and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassandraTable:\n",
    "    \"\"\"This Class represents a Cassandra's Table.\n",
    "\n",
    "        Args:\n",
    "            session: Cassandra's cluster session.\n",
    "            table_name : Table Name.\n",
    "\n",
    "        Attributes:\n",
    "            session: Cassandra's cluster session.\n",
    "            table_name : Table Name.\n",
    "            columns: Table columns.\n",
    "            columns_types: Table columns with types.\n",
    "            primary_key: Primary kye definition.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            session: cassandra.cluster.Session,\n",
    "            table_name: str) -> None:\n",
    "\n",
    "        self.session = session\n",
    "        self.columns: str = ''\n",
    "        self.columns_types: str = ''\n",
    "        self.table_name: str = table_name\n",
    "        self.primary_key: str = ''\n",
    "\n",
    "    def define_columns(self, columns: dict[str: str]):\n",
    "        \"\"\"This method generates the column definition.\n",
    "\n",
    "            Args:\n",
    "                columns: column definition dict where:\n",
    "                    keys: column name.\n",
    "                    values: column type.\n",
    "        \"\"\"\n",
    "        cols = [col for col in columns.keys()]\n",
    "        columns_types = [col + ' ' + col_type for col, col_type in columns.items()]\n",
    "\n",
    "        cols = ', '.join(cols)\n",
    "        columns_types = ', '.join(columns_types)\n",
    "\n",
    "        self.columns = cols\n",
    "        self.columns_types = columns_types\n",
    "\n",
    "        return self\n",
    "\n",
    "    def define_primary_key(self, primary_key: dict[str, list[str]]):\n",
    "        \"\"\"This method generates the primary key definition.\n",
    "\n",
    "            Args:\n",
    "                primary_key: column definition dict where:\n",
    "                    keys: type of key: partition or clustering.\n",
    "                    values: columns.\n",
    "        \"\"\"\n",
    "\n",
    "        partition = primary_key.get('partition', None)\n",
    "        partition = ', '.join(partition)\n",
    "\n",
    "        clustering = primary_key.get('clustering', '')\n",
    "        if clustering != '':\n",
    "            clustering = ', '.join(clustering)\n",
    "\n",
    "            self.primary_key = partition + ', ' + clustering\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.primary_key = partition\n",
    "\n",
    "        return self\n",
    "\n",
    "    def build(self) -> str:\n",
    "        \"\"\"This method generates the create query.\"\"\"\n",
    "\n",
    "        query = f\"CREATE TABLE IF NOT EXISTS {self.table_name}\"\n",
    "        query += '(' + self.columns_types + ', '\n",
    "        query += f'PRIMARY KEY ({self.primary_key})' + ')'\n",
    "\n",
    "        return query\n",
    "\n",
    "    def execute(self, echo: bool = True) -> None:\n",
    "        \"\"\"This method executes the create query.\"\"\"\n",
    "\n",
    "        query = self.build()\n",
    "\n",
    "        if echo:\n",
    "            print(query)\n",
    "\n",
    "        try:\n",
    "            rows = self.session.execute(query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        return rows\n",
    "\n",
    "    def drop(self) ->  None:\n",
    "        \"\"\"This method drops the table.\"\"\"\n",
    "\n",
    "        query = f'DROP TABLE {self.table_name}'\n",
    "\n",
    "        try:\n",
    "            session.execute(query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            \n",
    "class Query:\n",
    "    \"\"\"This Class represents a Cassandra's Query statement.\n",
    "\n",
    "        Args:\n",
    "            session: Cassandra's cluster session.\n",
    "\n",
    "        Attributes:\n",
    "            session: Cassandra's cluster session.\n",
    "            columns: Selected columns.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            session: cassandra.cluster.Session\n",
    "    ) -> None:\n",
    "\n",
    "        self.session = session\n",
    "        self.columns: str = ''\n",
    "        self.table_name: str = ''\n",
    "        self.where_value: str = ''\n",
    "\n",
    "    def select(self, columns: str):\n",
    "        \"\"\"This method is used to select columns.\n",
    "\n",
    "            Args:\n",
    "                columns: column to be selected\n",
    "        \"\"\"\n",
    "\n",
    "        self.select_columns = columns\n",
    "\n",
    "        return self\n",
    "\n",
    "    def from_table(self, table_name: str):\n",
    "        \"\"\"This method is used to define table name.\n",
    "\n",
    "            Args:\n",
    "                table_name: Table name.\n",
    "        \"\"\"\n",
    "        self.table_name = table_name\n",
    "\n",
    "        return self\n",
    "\n",
    "    def where(self, conditions: str):\n",
    "        \"\"\"This method is used to define WHERE Clause.\n",
    "\n",
    "            Args:\n",
    "                conditions: hardcoded where conditions.\n",
    "        \"\"\"\n",
    "        self.where_value = conditions\n",
    "\n",
    "        return self\n",
    "\n",
    "    def build(self) -> str:\n",
    "        \"\"\"This method generates the select query.\"\"\"\n",
    "\n",
    "        where_clause = ''\n",
    "\n",
    "        if self.where_value:\n",
    "            where_clause = f\"WHERE {self.where_value}\"\n",
    "\n",
    "        return f\"SELECT {self.select_columns} FROM {self.table_name} {where_clause}\"\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"This method executes the create query.\"\"\"\n",
    "\n",
    "        query = self.build()\n",
    "\n",
    "        try:\n",
    "            rows = self.session.execute(query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 1: Songs info by Session\n",
    "\n",
    "> Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4\n",
    "\n",
    "To fulfill this business requirement, we are going to create the following table structure:\n",
    "\n",
    "* Columns:\n",
    "    * `artirs`\n",
    "    * `iteminsession`\n",
    "    * `length`\n",
    "    * `sessionid`\n",
    "    * `song`\n",
    "* Primary Key:\n",
    "    * Partition Key: `sessionid`\n",
    "    * Clustering column: `iteminsession`\n",
    "\n",
    "Since we are going to filter by sessionid and iteminsession, we'll need to have both as a composed key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS songs_by_session(artist text, iteminsession int, length float, sessionid int, song text, PRIMARY KEY (sessionid, iteminsession))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x241d3594eb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_by_session_table = CassandraTable(\n",
    "    session=session,\n",
    "    table_name='songs_by_session'\n",
    ")\n",
    "\n",
    "songs_by_session_table.\\\n",
    "    define_columns(\n",
    "        columns={\n",
    "            'artist': 'text',\n",
    "            'iteminsession': 'int',\n",
    "            'length': 'float',\n",
    "            'sessionid': 'int',\n",
    "            'song': 'text',\n",
    "        }).\\\n",
    "    define_primary_key(\n",
    "        primary_key={\n",
    "            'partition': ['sessionid'],\n",
    "            'clustering': ['iteminsession']\n",
    "        }).\\\n",
    "    execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = f\"INSERT INTO {songs_by_session_table.table_name} \"\n",
    "        query += '(' + songs_by_session_table.columns + ')'\n",
    "        num_cols = len(songs_by_session_table.columns.split(','))\n",
    "        query += \"VALUES (\" + ('%s, ' * num_cols)[:-2] + ')'\n",
    "        session.execute(query, (line[0], int(line[3]), float(line[5]), int(line[8]), line[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT to verify that the data have been inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "query = Query(\n",
    "    session=session\n",
    ")\n",
    "\n",
    "rows = query.\\\n",
    "    select(\n",
    "        columns=\"artist, song, length\").\\\n",
    "    from_table(\n",
    "    table_name=songs_by_session_table.table_name).\\\n",
    "    where(\n",
    "    conditions=\"sessionid=338 and iteminsession=4\").\\\n",
    "    execute()\n",
    "\n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2: Songs played by user\n",
    "\n",
    "> Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "To fulfill this business requirement, we are going to create the following table structure:\n",
    "\n",
    "* Columns:\n",
    "    * `artirs`\n",
    "    * `song`\n",
    "    * `userid`\n",
    "    * `iteminsession`\n",
    "    * `first_name`\n",
    "    * `last_name`\n",
    "    * `sessionid`\n",
    "* Primary Key:\n",
    "    * Partition Key: `userid`\n",
    "    * Clustering column: `sessionid`, `iteminsession`\n",
    "    \n",
    "In this case we have included iteminsession as clustering column to sort the table by this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS artist_song_user(artist text, song text, userid int, iteminsession int, first_name text, last_name text, sessionid int, PRIMARY KEY (userid, sessionid, iteminsession))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x241d366ebe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_song_user = CassandraTable(\n",
    "    session=session,\n",
    "    table_name='artist_song_user'\n",
    ")\n",
    "\n",
    "artist_song_user.\\\n",
    "    define_columns(\n",
    "        columns={\n",
    "            'artist': 'text',\n",
    "            'song': 'text',\n",
    "            'userid': 'int',\n",
    "            'iteminsession': 'int',\n",
    "            'first_name': 'text',\n",
    "            'last_name': 'text',\n",
    "            'sessionid': 'int'\n",
    "        }).\\\n",
    "    define_primary_key(\n",
    "        primary_key={\n",
    "            'partition': ['userid'],\n",
    "            'clustering': ['sessionid', 'iteminsession']\n",
    "        }).\\\n",
    "    execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = f\"INSERT INTO {artist_song_user.table_name} \"\n",
    "        query += '(' + artist_song_user.columns + ')'\n",
    "        num_cols = len(artist_song_user.columns.split(','))\n",
    "        query += \"VALUES (\" + ('%s, ' * num_cols)[:-2] + ')'\n",
    "        session.execute(query, (line[0], line[9], int(line[10]), int(line[3]), line[1], line[4], int(line[8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT to verify that the data have been inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "query = Query(\n",
    "    session=session\n",
    ")\n",
    "\n",
    "rows = query.\\\n",
    "    select(\n",
    "        columns=\"artist, song, first_name, last_name\").\\\n",
    "    from_table(\n",
    "    table_name=artist_song_user.table_name).\\\n",
    "    where(\n",
    "    conditions=\"userid = 10 and sessionid = 182\").\\\n",
    "    execute()\n",
    "\n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 3: Songs played by user\n",
    "\n",
    "> Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "To fulfill this business requirement, we are going to create the following table structure:\n",
    "\n",
    "* Columns:\n",
    "    * `userid`\n",
    "    * `first_name`\n",
    "    * `last_name`\n",
    "    * `song`\n",
    "* Primary Key:\n",
    "    * Partition Key: `song`\n",
    "    * Clustering column: `userid`\n",
    "    \n",
    "In this case, we have included userid as a clustering column to avoid overwriting the song by a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS user_song_table(userid int, first_name text, last_name text, song text, PRIMARY KEY (song, userid))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x241d3720e80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_song_table = CassandraTable(\n",
    "    session=session,\n",
    "    table_name='user_song_table'\n",
    ")\n",
    "\n",
    "user_song_table.\\\n",
    "    define_columns(\n",
    "        columns={\n",
    "            'userid': 'int',\n",
    "            'first_name': 'text',\n",
    "            'last_name': 'text',\n",
    "            'song': 'text'\n",
    "        }).\\\n",
    "    define_primary_key(\n",
    "        primary_key={\n",
    "            'partition': ['song'],\n",
    "            'clustering': ['userid']\n",
    "        }).\\\n",
    "    execute()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = f\"INSERT INTO {user_song_table.table_name} \"\n",
    "        query += '(' + user_song_table.columns + ')'\n",
    "        num_cols = len(user_song_table.columns.split(','))\n",
    "        query += \"VALUES (\" + ('%s, ' * num_cols)[:-2] + ')'\n",
    "        session.execute(query, (int(line[10]), line[1], line[4], line[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT to verify that the data have been inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Jacqueline Lynch\n",
      "80 Tegan Levine\n",
      "95 Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "query = Query(\n",
    "    session=session\n",
    ")\n",
    "\n",
    "rows = query.\\\n",
    "    select(\n",
    "        columns=\"userid, first_name, last_name\").\\\n",
    "    from_table(\n",
    "    table_name=user_song_table.table_name).\\\n",
    "    where(\n",
    "    conditions=\"song='All Hands Against His Own'\").\\\n",
    "    execute()\n",
    "\n",
    "for row in rows:\n",
    "    print(row.userid, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_by_session_table.drop()\n",
    "artist_song_user.drop()\n",
    "user_song_table.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}